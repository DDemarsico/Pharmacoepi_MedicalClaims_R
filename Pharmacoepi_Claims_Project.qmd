---
title: "Pharmacoepi_Claims_Project"
format: html
editor: visual
---

# Pharmacoepidemiology: Claims Project:

## Overview:

This project will be focusing on assessing differences in treatment outcomes for Patients with Parkinson's Disease. The goal of this project is twofold:

1.  To assess if there is a significant difference in days from beginning Levodopa to a diagnosis of Parkinson's Disease with Dyskinesia between individuals using Levopdopa Monotherapy, Levodopa with Rasagiline, and Levodopa with Pramipexole.

2.  To assess if there are regional differences in prescribing frequency for our treatment arms, and if there are differences between prescriber specialty and treatment group.

As a result, I'll be splitting this code into two sections.

### Packages:

```{r}
library(tidyverse) # For all your tidy needs
library(ggeffects) # Used for predictive plotting
library(psych)     # I like this for easy summary stats
library(plotly)    # Interactive plots in ggplot
library(AER)       # Used for dispersion testing
library(car)       # Used for Negative Binomial Regression
library(MASS)      # Used for backwards selection testing
library(broom)     # Used for tidying reports for easy interpretation
library(emmeans)   # Used to find EMMeans for logistic regression
library(nnet)      # Used for multinomial logistic regression
library(MuMIn)     # USed for backwards selection in multinom()
library(gtsummary) # Used for pretty table 1s
library(knitr)     # Used for exporting tables
library(gt)
library(htmlwidgets)
```

### Data Import:

The data was originally sent to be as a SAS file. The form was transformed to a CSV in SAS studio prior to work. Let's import the completed CSV.

```{r}
data <- read.csv("C:\\Users\\domin\\Downloads\\dd_analytic.csv") 
```

# Data Overview:

## Summary Statistics:

Great, let's start by looking at some summary statistics:

```{r}

summary(data)
```

Ok, a quick overview:

### Treatment Arm:

Our total sample size is 1297 patients. The mean for rasagiline use and pramipexole use (both are binary variables) is .1164 and .118 respectively. Therefore, there are quite a few more patients on levodopa monotherapy. Approximately 23% of our total patient population is using some form of dual therapy with levodopa.

Let's confirm this number:

```{r}

# I also want to check if there are any overlapping records that are using both rasagiline or Pramipexole:

data$bothTx <- ifelse(data$rasagiline == 1 & data$pramipexole == 1, 1, 0)
table(data$bothTx)

# Ok there are 24 patients that are using both Rasagiline and Pramipexole. I want to alter the previous identification variables to remove these patients and only have them stored in the the BothTx variable:

data$rasagiline <- ifelse(data$rasagiline == 1 & data$bothTx == 0, 1, 0)
data$pramipexole <- ifelse(data$pramipexole == 1 & data$bothTx == 0, 1, 0)

# Now let's review the final numbers

table(data$rasagiline)
table(data$pramipexole)
table(data$bothTx)

```

-   Total N: 1297

-   Total Patients Dual therapy with Rasagiline: 127 (\~10%)

-   Total Patients Dual therapy with Pramipexole: 129 (\~10%)

-   Total Patients Therapy with all 3 groups: 24 (\~2%)

-   Total Patients on any form of Dual Therapy: 280 (\~23%)

-   Total Patients using Levodopa Monotherapy: 1017 (\~77%)

Great, let's create two separate variables using this info. I want one variable with the original 3 categories, and an exploratory variable with the dual therapy arm

```{r}

# Let's mutate the results of the other variables into a the primary categorical variable
data <- data %>%
  mutate(tx_group = case_when(
    rasagiline == 1 ~ "Rasagiline",
    pramipexole == 1 ~ "Pramipexole",
    TRUE ~ "Levodopa Monotherapy"
  ))

data$tx_group <- factor(data$tx_group)

# Now let's do the same for the experimental arm

data <- data %>%
  mutate(tx_group_exp = case_when(
    rasagiline == 1 ~ "Rasagiline",
    pramipexole == 1 ~ "Pramipexole",
    bothTx == 1 ~ "Both",
    TRUE ~ "Levodopa Monotherapy"
  ))

# Now let's create a new dataframe without the "both" group:

data2 <- data %>%
  filter(tx_group_exp != "Both")





# And finally, let's set each variable to have levodopa as it's reference variable
data2$tx_group <- relevel(data2$tx_group, ref = "Levodopa Monotherapy")

table(data2$tx_group)
```

### Days to Dx

Our primary outcome measure for Aim 1 is the time to Dx of PD w/ Dyskinesia from the Index Date (the start date for levodopa). Currently the index date and dx date are both stored in a character variable with the date in YYYY-MM-DD format. We'll need to take the difference of these two dates to find the amount in days.

```{r}

# First, we'll need to change the dates from a character to a date variable

data$index_date <- as.Date(data$index_dt, format  = "%Y-%m-%d")
data$dx_date <- as.Date(data$pd_dyskinesia_dt, format  = "%Y-%m-%d")

# Now we can take the difference between these dates.
data$days2dx <- as.numeric(data$dx_date - data$index_date)

# Now let's check our results:
summary(data$days2dx)

# Mean number of days is ~960 days or 2.63 years. Since our data needs to be considerd a 'count', let's make sure all of the values are integers"
unique(data$days2dx)


```

This data already looks very good. However, there are quite a few lower day counts within this dataset. For example, we have 1 patient that took Levodopa on the index date, and immediately returned the next day to have have an updated dx.

This strikes me as a situation where the clinician provided a dose which was much too high for the patient. The focus of this project is to focus on a stereotypical case where the dose of levodopa is proportionately small relative to the patient's needs.

Given this fact, I think it would be prudent to separate this dataset to remove the patients that have a diagnosis within 30 days of index.

```{r}

# Let's create a new data frame 
data2 <- data %>%
  filter(days2dx >= 30)

# Now let's check the unique values to see if anything changed:
unique(data2$days2dx)

# Great, this removed all of the lower values, let's check to see what our working N is now:
table(data2$rasagiline)
table(data2$pramipexole)
table(data2$bothTx)

```

After removing our the lower values from our sample of days to dx, we settled on our final count of:

-   **Total N: 1282 - Removed 15 patients**

-   **Rasagiline Dual: 127**

-   **Pramipexole Dual: 128**

-   **Rasagiline & Pramipexole: 24**

-   **Levodopa Monotherapy: 1,003**

This distribution shows us that of the 15 patients that were removed, 14 of them were in the Levodopa Monotherapy group, and 1 of them was in the Pramipexole Dual Therapy group.

This aligns with the idea that the initial dose was incorrectly prescribed by the clinician or interacted with the 1 patient's pramipexole dose.

Now let's visualize this variable

```{r}
hist(data2$days2dx, breaks = 30, main = "Histogram of Days2Dx", xlab = "Count", col = "skyblue")

```

### Obese/Underweight

Sinemet (Carbidopa/Levodopa) is given in relatively large quantities, therefore it is hypothesized that weight/size may have an impact on whether or not the concentration of Levodopa is sufficient to elicit dyskinesia.

```{r}

# Let's start by assessing the rates of Obsese/Underweight Patients
table(data2$obese)
table(data2$underweight)
```

Only 5 patients were categorized as obese, and only 2 patients were categorized as underweight. These numbers are far too low for analysis, and will not be utilized.

### Age

Another interesting covariate will be age. This is rather simple, let's get a general overview of the age distribution

```{r}

summary(data2$age)

# There looks to be a minimum value of 12, which is quite weird as PD is mostly a young person's disease. Let's take a look at the unique values

unique(data2$age)

# Upon the review, there are two values of 12 and 17, which are far too young for this study. This makes me feel that this was a data entry error. Let's create a new dataframe that removes these subjects.


```

Upon the review, there are two values of 12 and 17, which are far too young for this study. This makes me feel that this was a data entry error. Let's create a new dataframe that removes these subjects.

```{r}

# Let's create a new data frame 
data2 <- data2 %>%
  filter(age >= 30)

# Now let's check the unique values to see if anything changed:
unique(data2$age)

summary(data2$age)

# Great, this removed all of the lower values, let's check to see what our working N is now:
table(data2$rasagiline)
table(data2$pramipexole)
```

-   Total N = 1278 - 4 Patients Removed

-   Rasagiline = 127

-   Pramipexole = 127

-   Both = 24

-   Monotherapy = 1,000

This breakdown show 4 more patients removed from the data frame. 3 of which were from the Monotherapy group and 1 was from the Pramipexole group.

### Sex:

Same situation with Sex, we'll want to assess the distribution to see if there are strange differences in the distribution

```{r}

table(data2$der_sex)

# 513 Females and 765 Males. This is suficient, let's make this a binary variable.

data2$sex <- ifelse(data2$der_sex == "F", "Female", "Male")
table(data2$sex)

# Now let's make it a factor for easy use:
data2$sex <- as.factor(data2$sex)
```

513 Females and 765 Males. This is sufficient for use in our models.

### State & Region

There are two variables for both state and region, respectively. I want to look at our state variable first to assess rates, and then we can assess the region variable to determine if there are different bins that we want for our state.

```{r}

table(data2$pat_state)

# We have data for only 42 states. Let's check how the region grouping worked

table(data2$pat_region)

```

This regional distribution is much neater. This will most likely be the value used in further analysis. The only issue is that there are 16 patients that are not set to any location. Let's set these values to be NA.

```{r}

# Let's create a new variable with the approriate settings.
data2 <- data2 %>%
  mutate(pat_region = case_when(
    pat_region == "MW" ~ "Midwest",
    pat_region == "NE" ~ "Northeast",
    pat_region == "S"  ~ "South",
    pat_region == "W"  ~ "West",
    TRUE ~ NA
  ))


data2$pat_region <- as.factor(data2$pat_region)
table(data2$pat_region)
```

### Insurance:

Same thing with Insurance. Let's make sure the distributions aren't strange.

```{r}

table(data2$insurance_new)

  # 496 patients wil commercial insurance, and 774 with governemnt, and 8 other. Let's make this into a factor

data2 <- data2 %>%
  mutate(insurance = case_when(
    insurance_new == "C" ~ "Commercial",
    insurance_new == "G" ~ "Government",
    TRUE ~ NA
  ))

data2$insurance <- as.factor(data2$insurance)
data2$insurance <- relevel(data2$insurance, ref = "Government")

```

496 on commercial, 774 on Government, and 8 on Other. This distribution is perfectly fine.

### Specialist?

I also want to know the rates of which specialists prescribe the medications of interest. Let's take a peek at those as well

```{r}

table(data2$specialist_levodopa)
table(data2$specialist_rasagiline)
table(data2$specialist_pramipexole)

```

-   We have info on 785 patients for levodopa and \~86% (687) of patients received levodopa from a specialist.

-   We have info on 95 patients for Rasagiline and \~94% (89) of patients received rasagiline from a specialist

-   We have info on 99 patients for Pramipexole and \~85% of patients received pramipexole from a specialist.

This isn't a huge sample size, but it is sufficient for some interesting questions. It would be interesting to compare the few subjects that received care not from a specialist, and look at their rates. Let's make a new variable for this:

```{r}

# First, let's create a new variable by going row by row determining our values

data2 <- data2 %>%
  rowwise() %>%
  mutate(
    pcp = case_when(
      all(is.na(c_across(c(specialist_levodopa, specialist_pramipexole,          specialist_rasagiline)))) ~ NA_real_,              # All are NA
      any(c_across(c(specialist_levodopa, specialist_pramipexole,                specialist_rasagiline)) == 0, na.rm = TRUE) ~ 1,         # Any 0
      any(c_across(c(specialist_levodopa, specialist_pramipexole,                specialist_rasagiline)) == 1, na.rm = TRUE) ~ 0,         # Any 1
      TRUE ~ NA_real_                           # Catch-all for other NA combos
    )
  ) %>%
  ungroup()

# Now let's check to see if this worked
table(data2$pcp)

# And finally let's make this a factor
data2$pcp <- as.factor(data2$pcp)
# And set the levels
levels(data2$pcp) <- c("Specialist", "PCP")
```

Great, we have a total of 110 patients that are considered to have not received care by a neurology specialist during their time in the study.

### Charleson Comorbidity Score

Finally, let's check the CCS to determine if the distribution seems ok.

```{r}

# Let's check frequency first
table(data2$cqci)

# OK, this makes sense, more people who are generally healthy, so a natural right skew.

summary(data2$cqci)

# Mean is 1.261

hist(data2$cqci)
```

Definitely right-skewed, but is definitely usable.

## Table 1:

Great, now let's create a nice table 1 to summarize our final population.

```{r, results='asis'}

tbl1 <- data2 %>%
  select(days2dx, age, tx_group, sex, insurance, cqci, pcp, pat_region) %>%
  tbl_summary(by = tx_group, missing = "no") %>%
  modify_header(label ~ "**Variable**") %>%
  bold_labels() %>%
  modify_caption("**Table 1.** Baseline Characteristics") %>%
  as_gt()

tbl1

# Save this file as it's own thing:

gtsave(tbl1, "C:\\Users\\domin\\OneDrive\\Documents\\GitHub\\DDemarsico.github.io\\Pharmacoepi_Claims_Project_R\\Pharmacoepi_Claims_Project_files\\figure-html\\table1.html")
# Let's view it in broswer just in case.
browseURL("C:\\Users\\domin\\OneDrive\\Documents\\GitHub\\DDemarsico.github.io\\Pharmacoepi_Claims_Project_R\\Pharmacoepi_Claims_Project_files\\figure-html\\table1.html")
```

## Power Analysis:

### Aim 1:

Let's start looking at our sample size and seeing what our power would be. For both of my aims, I'm really unsure as to what my effect size would be. Using clinical judgement, I don't think this effect will really be too large. I feel an upper limit of a 30% change would be quite substantial, so I'll move with a exp(.3) as my effect size

```{r}

exp(.3)
# Effect size = 1.34
```

There isn't a package that simulates my power, so i'll have to build the function myself.

```{r}



# Let's start by building A Function to simulate and test treatment effect
sim_power_nb <- function(n = 1278, reps = 1000, effect = log(1.34)) {
  sig_count <- 0
  
  for (i in 1:reps) {
    treatment <- factor(sample(c("A", "B", "C"), n, replace = TRUE))
    X <- model.matrix(~ treatment)[, -1]  # drop intercept
    
    # Simulate linear predictor with desired effect
    lp <- effect * (treatment == "B") + effect * 0.5 * (treatment == "C")
    mu <- exp(lp)
    
    # Simulate NB outcome
    y <- rnbinom(n, mu = mu, size = 1)  # size = dispersion parameter
    
    # Fit model
    fit <- glm.nb(y ~ treatment)
    pval <- summary(fit)$coefficients[2, 4]  # p-value for treatmentB vs A
    
    if (!is.na(pval) && pval < 0.05) sig_count <- sig_count + 1
  }
  
  sig_count / reps
}

# Run power simulation
set.seed(123)
sim_power_nb()

```

Calculated power = .866 of 86.6%. We're in the clear!

### Aim 2:

We'll need to do the same thing for Aim 2. Clinically, I can't forsee larger than 30% effect sizes, so let's move forward with the same effect size: .3

Additionally, I'll need to simulate my power using the information I know now once again, but for logistic regression rather than negative binomial.

```{r}
simulate_multinom_power <- function(n = 1278, reps = 1000, alpha = 0.05) {
  sig_count <- 0
  
  for (i in 1:reps) {
    # Simulate region variable (4 levels)
    pat_region <- factor(sample(c("North", "South", "East", "West"), n, replace = TRUE))
    
    # Create design matrix for region (without intercept)
    region_matrix <- model.matrix(~ pat_region)[, -1]

    # Define linear predictors for treatment group B and C (vs A)
    # Adjust effect size here as needed â€” this example adds a region effect
    lp_B <- 0.3 * (pat_region == "South") + 0.3 * (pat_region == "East")
    lp_C <- 0.3 * (pat_region == "West") + 0.3 * (pat_region == "South")

    # Calculate probabilities via softmax
    pA <- 1
    pB <- exp(lp_B)
    pC <- exp(lp_C)
    total <- pA + pB + pC
    probs <- cbind(pA / total, pB / total, pC / total)
    
    # Sample tx_group from the probabilities
    tx_group <- apply(probs, 1, function(p) sample(c("A", "B", "C"), size = 1, prob = p))

    # Fit multinomial logistic regression
    model <- multinom(as.factor(tx_group) ~ pat_region, trace = FALSE)

    # Extract p-values for overall region effect (Type III-style)
    pvals <- summary(model)$coefficients
    se <- summary(model)$standard.errors
    z_scores <- pvals / se
    p_values <- 2 * (1 - pnorm(abs(z_scores)))

    # Check if any p-value for region levels is significant in either outcome (B or C vs A)
    if (any(p_values < alpha)) {
      sig_count <- sig_count + 1
    }
  }

  # Return estimated power
  sig_count / reps
}

# Example: Run simulation with 1278 participants
set.seed(123)
simulate_multinom_power()

```

Our simulated power = 87.5. Lovely.

# Aim 1:

## Poisson or Negative Binomial

The goal of Aim 1 is to assess if there are any differences in the number of days between starting Levodopa and diagnosis of PD w/ Dyskinesia. I am considering using either a Poisson or a Negative Binomial Regression for this data, as the primary outcome is discrete (individual days). To determine which we will use, let's test the dispersion of our most basic model using our 'days2dx' variable and treatment arm variable.

```{r}

# First let's fit a fully reduced model with only the treatment groups and days2dx

base_poisson <- glm(days2dx ~ tx_group, family = poisson, data = data2)

# Now let's see if this fits the dispersion test:

dispersiontest(base_poisson)

# p-value of <.001. Therefore the data is overdispersed.

# let's also test to see if the variance exceeds the mean.
var(data2$days2dx)

# mean = 971, variance = 229528
```

Our Dispersion test of our Univariate model shows dispersion. Therefore, we will need to utilize a negative binomial regression.

### NBR basics:

There are 5 assumptions necessary for a Negative Binomial Regression:

-   A Count Dependent Variable - **CONFIRMED**

-   Overdispersion - **CONFIRMED**

-   Independence of Observations - **CONFIRMED**

-   Linearity of Log-Link Function

-   Multicollinearity

Let's start by running the basic univariate structure

This is assumes that the log of the expected count is a linear function of the predictors. To test this, we'll use a Component + Residual plots to test for non-linearity:

```{r}


# First let's run the univariate negative binomial regression
neg_bin_base <- glm.nb(days2dx ~ tx_group, data = data2)
summary(neg_bin_base)

# Univariate Analysis reveals a statistically significant relationship with Rasagiline but not with Pramipexole. Let's exponentiate the results to see actual rates.
exp(coef(neg_bin_base))
exp(confint(neg_bin_base))


```

On Average, a patient starting Levodopa Monotherapy is expected to take 941 days to reach a diagnosis of PD w/ Dyskinesia. The Pramipexole group is approaching significance (p = .07, CI: .99 1.25), but the Rasagiline group has a rate of 1.20 (p = .003, CI: 1.07, 1.36).

**Put plainly, individuals who were taking pramipexole dual-therapy range from taking 1% less days to 25% more days to reach dx. While not Statistically Significant, this is definitely clinically significant.**

**Indivduals who were taking Rasagiline dual-therapy, on average, take 20% longer to reach a diagnosis of Parkinson's Disease w/ Dyskinesia, with a range of 7% longer up to 36% longer. If a levodopa monotherapy patient takes 941 days to reach dx on average, a patient taking rasagiline would take 1129 days on average (almost 2/3 of a year). In the best possible scenario, these patients would take up to 339 days longer.**

## Multivariate Analysis:

Great, now that we have significant results from the Univariate analysis, let's begin model selection for a multivariate analysis.

For this portion, I'll begin by using a saturated model for our NBR. The additional covariates will include:

-   Age

-   Sex

-   Insurance:

-   Specialist

-   CCS

```{r}

# Let's fit the data to model to only use rows that are completed
vars_used <- all.vars(days2dx ~ tx_group + age + sex + insurance + pcp + cqci)  

data2_clean <- data2[complete.cases(data2[, vars_used]), ]

# Let's begin with our saturated model first and see if there are different results when controlling for additional factors.

neg_bin_saturated <- glm.nb(days2dx ~ tx_group + cqci + age + sex + insurance + pcp, data = data2_clean)
summary(neg_bin_saturated)


#library(ggeffects)
ggpredict(neg_bin_saturated, terms = c("cqci", "tx_group"))
```

OK, a fully saturated model still shows statistical significance for Rasagiline Use, age, and a strong association with CCS scores.

Let's do run AIC/BIC on this model to see what the review of a reduced model might look like.

```{r}

# Let's start by running AIC and then we can move to BIC for model comparison.
step_model_aic <- step(neg_bin_saturated, direction = "backward")  

# AIC selects a model of treatment group, age, and CCS. This makes intuitive clinical sense


# Let's run BIC
step_model_bic <- step(neg_bin_saturated, direction = "backward", k = log(nrow(data2_clean)))
summary(step_model_bic)

# BIC chooses a fully reduced model with only cqci. This doesn't make too much clinical sense, as our primary explanatory variable isn't involved at all. 
```

Both AIC and BIC preferred a reduced model. However, BIC preferred a model with only CCS. This doesn't make any intuitive sense. AIC however, was more flexible and preferred a model with Treatment Group, Age, and CCS. This makes the most clinical sense, and will be our preferred model for Aim 1.

## Results:

Let's run this one more time and get some final numbers:

```{r}

# Run the model
neg_bin_final <- glm.nb(days2dx ~ tx_group + age + cqci, data = data2_clean)
summary(neg_bin_final)

# Exponentiate to get interpretable results:
exp(coef(neg_bin_final))
exp(confint(neg_bin_final))



```

**When adjusting for age and Charleson comorbidity score, Individuals starting Levodopa monotherapy had an average time to diagnosis of \~702 days.**

-   **When controlling for Age and CCS, Individuals taking Rasagiline Dual-Therapy took, on average, 21% longer than expected to reach their diagnosis (p = .007, CI:1.06-1.41). This is both statistically and clinically significant.**

-   **When controlling for Age and CCS, Individuals taking Pramipexole Dual-Therapy took, on average, \~9% longer than expected to reach their diagnosis (p = .228, CI: 0.95-1.25). While not statistically significant, this is possibly clinically significant if a patient cannot tolerate Rasagiline.**

-   **When controlling for Treatment group and CCS, a 1-unit increase in age was associated with a .06% increase in time to dx (p = .021, 1.00-1.01). This suggests that individuals that develop Parkinson's Disease Earlier in life may have a worse prognosis for disease progression speed.**

-   **When controlling for Treatment group and Age, a 1-unit increase in CCS was associated with a 8% decrease in time to diagnosis (p \< .001 , CI: 0.90 - 0.93). This makes intuitive sense, as patients that are generally sicker will be less resilient to disease progression and will require more intensive treatment.**

### Assumptions:

Let's check our two remaining assumptions: Multicollinearity and Linearity of the Log-Link Function

#### Multicollinearity:

```{r}

# Multicollinearity can be assess by checking the VIF (Variance Inflation Factor): If the VIF is greater than 5, there is moderate concern. If the VIF is greater than 10, it's of severe concern.
vif(neg_bin_final)

# VIF is not greater than 1.06 for any variable. There is no multicollinearity.

```

#### Linearity of the Log-Link Function:

```{r}

# Linearity only matters for continous or ordinal variables. So we will only need to assess Age and CCS. This can be checked by component + residual plot.
crPlots(neg_bin_final)
```

There are some slight deviations, but overall, the relationship looks quite linear.

### Visualization

Great, now let's create some finished charts for our review:

Let's start by assessing our predicted values vs our observed values:

```{r}


# Predict count for each treatment group, holding age and score at their mean
plot_data <-ggpredict(neg_bin_final, terms = c("tx_group", "age [mean]", "cqci [mean]"))


# Plot it
plot1 <- ggplot(plot_data, aes(x = x, y = predicted, color = x)) +
  geom_point(size = 3) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(title = "Adjusted Predicted Counts by Treatment Group with Age + CCS scores held at Mean Value",
       x = "Treatment Group", y = "Days to Dx") +
  theme_minimal()


plotly1 <- ggplotly(plot1)
plotly1



plotly_built <- plotly::plotly_build(plotly1)

#export as a widget
htmlwidgets::saveWidget(plotly1, file = "C:\\Users\\domin\\OneDrive\\Documents\\GitHub\\DDemarsico.github.io\\Pharmacoepi_Claims_Project_R\\Pharmacoepi_Claims_Project_files\\figure-html\\my_plot.html", selfcontained = TRUE)

```

Now I want to do the same chart, but predicted to have the CQCI score at 0, rather than the mean. This will help us determine if there is a noticeable difference between patients that are normal or very sick.

```{r}

# Predict count for each treatment group, holding age at mean and CCS score at 0
plot_data <-ggpredict(neg_bin_final, terms = c("tx_group", "age [mean]", "cqci [0]"))


# Plot it
plot2 <- ggplot(plot_data, aes(x = x, y = predicted, color = x)) +
  geom_point(size = 3) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(title = "Adjusted Predicted Counts by Treatment Group with CCI at 0 and age at Mean",
       x = "Treatment Group", y = "Days to Dx") +
  theme_minimal()

ggplotly(plot2)
```

Now let's do the same thing, but with CQCI at 12:

```{r}
# Predict count for each treatment group, holding age at mean and CCS score at 12
plot_data <-ggpredict(neg_bin_final, terms = c("tx_group", "age [mean]", "cqci [12]"))


# Plot it
plot3 <- ggplot(plot_data, aes(x = x, y = predicted, color = x)) +
  geom_point(size = 3) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(title = "Adjusted Predicted Counts by Treatment Group with CCI at 12 and age at Mean",
       x = "Treatment Group", y = "Days to Dx") +
  theme_minimal()

ggplotly(plot3)
```

Great, now that we've seen how this looks at specific points. Let take a look at the average of all given points (i.e. estimated marginal means.)

```{r}
# Now let's plot this
em <- emmeans(neg_bin_final, ~ tx_group, type = "response")

# Now let's move this to ggplot to make it more beautiful
em_df <- as.data.frame(em)

# Our EMMEans are need to be exponentiated, let's set this right
names(em_df)

em2 <- ggplot(em_df, aes(x = tx_group, y = response, color = tx_group)) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.1) +
   geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL), alpha = 0.2) +
    labs(title = "EMMeans for Final Model", y = "Estimated marginal mean (Days2Dx)", x = "Treatment group") +
    theme_minimal() 
    
  
em2_final <- ggplotly(em2)
em2_final
```

This is great! When averaging all possible predictions (instead of placing predictions at specific points. We can see that Rasagiline is, in fact, superior to levodopa monotherapy. Additionally, Pramipexole has demonstrated clinical significance. The Emmeans chart takes the average of all combinations rather than setting it at one point.

A Definition of estimated marginal means tells you what the model PREDICTS for each group or condition, after accounting for (or controlling for) other covariates in the model.

**THIS SHOWS THAT RASAGILINE DUAL-THERAPY IS SHOWING CLEARLY BETTER RESULTS. However, since this is not an RCT, we cannot say with certainty that this therapy shows superiority. However, we can say that clinical outcomes with this population show clinical significance for the use of rasagiline dual therapy over Levodopa Monotherapy.**

View 3 (OPTIONAL)

```{r}
data2_clean$predicted <- predict(neg_bin_final, type = "response")

ggplot(data2_clean, aes(x = tx_group, y = days2dx)) +
  geom_jitter(width = 0.1, alpha = 0.5) +
  stat_summary(aes(y = predicted), fun = mean, geom = "point", size = 3, color = "red") +
  labs(title = "Observed vs Adjusted Predicted Counts by Treatment Group",
       x = "Treatment", y = "Count") +
  theme_minimal()
```

# Aim 2:

We can now move on to Aim 2. Now that we have evidence of Dual-Therapy being more effective at increasing time to Dyskinesia Development, I want to start to explore the rates of use between regions. We currently have two variables to explore this, Region and State.

## Regional Exploration

The issue with the Region variable is that it came previously attached with 4 levels: South, Mw, NE, and West. Let's look at the distributions.

```{r}
table(data2_clean$pat_region)
```

### Region x Tx group

Ok, Let's start by looking at the rates of any use by region.

```{r}

# Let's start by looking at the numbers
table(data2_clean$pat_region, data2_clean$tx_group)

# This is helpful but I can't really see distributions. let's plot this.
ggplot(data2_clean, aes(x = pat_region, fill = tx_group)) +
  geom_bar(position = "dodge") +
  labs(title = "Medication Use by Region", y = "Frequency") +
  theme_minimal()
```

Interesting, this shows a lot of the counts, but not necessarily the distributions. Let's see if we can plot this with percentages rather than counts.

```{r}

# Let's begin by making a new dataframe in the long format
df_summary <- data2_clean %>%
  filter(!is.na(pat_region)) %>%
  group_by(pat_region, tx_group) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(pat_region) %>%
  mutate(Percent = Count / sum(Count) * 100)


ggplot(df_summary, aes(x = pat_region, y = Percent, fill = tx_group)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_text(aes(label = round(Percent, 1)),
            position = position_dodge(width = 0.9),
            vjust = -0.3, size = 3) +
  labs(title = "Treatment Group Distribution by Region",
       x = "Region", y = "Percentage") +
  theme_minimal()
```

Ok, this is a noticeable difference. Nationally, Levodopa monotherapy is by-far the largest treatment group. In fact, at it's lowest point (the west), Levodopa Monotherapy is used by 72.5% of sampled patients. Most regions follow a similar pattern: Levodopa monotherapy dominance, Pramipexole Dual Therapy use is the lowest, and Rasagiline Dual Therapy use is the second highest.

However, the Midwest breaks that trend. For patients in the Midwest, 82.8% of patients are using Levodopa Monotherapy, 11% of patients are using Pramipexole Dual-Therapy, and only 6.3% of patients are using rasagiline dual-therapy. This not only shows the highest amount of Levodopa use, but also inverts the use characteristics of the other regions.

### Region x Specialist

This inversion of expectations in the treatment distirubtion is surprising. A general hypothesis would have to relate to provider status, with specialist prescribing dual-therapy more often than PCPs. Let's look at the distribution of patients using a specialist or PCP to get their PD meds.

```{r}
# Let's begin filtering our our data for only patients with region and pcp
df_summary2 <- data2_clean %>%
  filter(!is.na(pat_region)) %>%
  group_by(pat_region, pcp) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(pat_region) %>%
  mutate(Percent = Count / sum(Count) * 100)


ggplot(df_summary2, aes(x = pat_region, y = Percent, fill = pcp)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_text(aes(label = round(Percent, 1)),
            position = position_dodge(width = 0.9),
            vjust = -0.3, size = 3) +
  labs(title = "PCP/Specialist use by Region",
       x = "Region", y = "Percentage") +
  theme_minimal()
```

Interesting findings, the Midwest did poorlu on the Tx group distribution and did poorly on this as well. The Midwest has the highest amount of PCP use (15.7%) for PD medications, where the West has the smallest amount of PCP use. This is a noticeable difference, but not anything truly ground breaking.

The aspect which is noticeable to me is how dominant Levodopa monotherapy is across the country. While certain regions are better at prescribing this drug pairing, it still pales in comparison to nuanced care.

### Region x Insurance

Now I want to do the same thing but for insurance type. I want to make sure that this issue isn't related to SES. In this dataset, insurance type is the closest thing I have to an SES measure.

```{r}
# Let's begin filtering our our data for only patients with region and pcp
df_summary3 <- data2_clean %>%
  filter(!is.na(pat_region)) %>%
  group_by(pat_region, insurance) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(pat_region) %>%
  mutate(Percent = Count / sum(Count) * 100)


ggplot(df_summary3, aes(x = pat_region, y = Percent, fill = insurance)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  geom_text(aes(label = round(Percent, 1)),
            position = position_dodge(width = 0.9),
            vjust = -0.3, size = 3) +
  labs(title = "Insurance type by Region",
       x = "Region", y = "Percentage") +
  theme_minimal()
```

Now this was unexpected. The Midwest has the highest rate of Government based insurance in comparison to every other region of the US. Whereas the West has the highest amount of commercial insurance when compared to the rest of the US. This data seems highly variable, but it may lead to an interesting covariate.

## Regression Analysis:

### Region x Tx

To test this, i want to look a logistic regression to see if we can predict this.

```{r}
# First, let's take a peak at the regression:

tx_region <- multinom(tx_group ~ pat_region, data = data2_clean)
summary(tx_region)
tidy(tx_region) # This just grabs all the results on puts it into a table.
```

Individuals in the Midwest (Reference) are:

-   -2.02 log odds of being on pramipexole over Levodopa. \* Significant

-   -2.58 log odds of being on rasagiline over levodopa. \* Significant

Individuals in the Northeast are:

-   .20 log odds greater odds (1.22 times) of being on pramipexole over levodopa mono than those in the midwest - Not Sig (.53)

-   .89 greater log odds (2.43 times) of being on rasagiline over levodopa mono than those in the midwest. Sig p = .009

Individuals in the South are:

-   -.04 log odds less likely (0.96 times) of being on pramipexole over levodopa monothan those in the MW - Not sig (.87)

-   .69 log odds greater (1.99 times) of being on Rasagiline over levodopa mono than those in the MW - Sig (p = .04)

Individuals in the West are:

-   .12 greater log odds (1.12 times) of being on Pramipexole over levodopa mono than those in the MW - Not sig (.72)

-   1.11 greater log odds (3.03 times) of being on Rasagiline over levodopa mono than those in the MW - Sig (.0006)

**Every other region has a greater odds of being on Rasagiline Dual-Therapy than the MW.**

### Region x Provider

Now I want to do the same thing but for provider type.

```{r}

pcp_region <- multinom(pcp ~ pat_region, data = data2_clean)
summary(pcp_region)
tidy(pcp_region)
```

For Individuals in the Northeast:

-   Patients had a -.30 (.0.74 times) log odds of using a PCP than those in the Midwest. Not sig: (.34)

For Individuals in the South:

-   Patients had a -.14 (0.60 times) log odds of using a PCP than those in the Midwest: Not sig (.59)

For Individuals in the West:

-   Patients had a -.51 log odds ((.60 times) of using a PCP than those in the MidWest: Not sig(.12)

**There is not a significant difference between PCP usage.**

### Region x Insurance

Finally, I want to look at the regional differences between Insurance and Region:

```{r}
insurance_region <- multinom(insurance ~ pat_region, data = data2_clean)
summary(insurance_region)
tidy(insurance_region)
```

For individuals living in the Northeast:

-   They have a 0.79 log odds (2.20 times) greater of being of being on commercial insurance in comparison to those in the midwest. Sig (p = .0003)

For Individuals living in the South:

-   They have a 1.45 log odds (4.26 times) greater of being on commercial insurance in comparison to those in the midwest. Sig (p \< .001)

For Individuals living in the West:

-   They have a 3.13 (22.87 times) log odds less of being on commercial insurance in comparison to those in the midwest. Sig (p\<.001)

**The Midwest has the highest rate of government insurance by a mile. The difference between the midwest and the west is 22 times. Quite significant. This could be showing an overall trend of lower SES in the Midwest when compared to most other parts of the country.**

## Saturated Regression:

Excellent, now we know that there are signficant regional differences in treatment type and insurance. Let's build out a model with treatment type as our primary dependent variable. Our independent variables will include:

-   Region

-   Specialist

-   Age

-   Sex

-   Insurance.

```{r}

# Let's build out the saturated model
aim2_saturated <- multinom(tx_group ~ pat_region + age + der_sex + pcp + insurance + cqci, data = data2_clean)

# Let's take a quick look.
summary(aim2_saturated)
tidy(aim2_saturated)
```

### AIC/BIC

Ok this looks good. However, the mass amount of covariates is making this difficult to interpret. Let's run AIC again to help select our final model.

```{r}

# Let's start with AIC:
AIC(aim2_saturated)     # Saturated: 1006.638

# Set this to fail if there are NAs.
options(na.action = "na.fail")  # required for dredge()

# dredge does exhaustive model search based on AIC
model_best_fit <- dredge(aim2_saturated)
model_best_fit

# Now reset the options so we can work again
options(na.action = "na.omit")
```

### Reduced Model:

The best model shouws and AIC of 1019.3 with a reduced model of Age, Sex, and Region. This drops insurance, PCP, and Charlson Comorbidity.

Let's run this model and see our results

```{r}
# Let's build out the saturated model
aim2_reduced <- multinom(tx_group ~ pat_region + age + sex, data = data2_clean)

# Let's take a quick look.
summary(aim2_reduced)
tidy(aim2_reduced)
```

## Assumptions:

### Independence::

Not necessary as each value was collected from independent patients

### Multicollinearity:

Let's asses the VIF of this model and see what we find:

```{r}
vif(aim2_reduced)

# The VIF is very high for age, let's try to scale the variable and see if that gets rid of the high value.
data2_clean$age_std <- scale(data2_clean$age)

# Now let's run the model again, but with our final model:
aim2_reduced_final <- multinom(tx_group ~ pat_region + age_std + sex, data = data2_clean)

vif(aim2_reduced_final)
# Significantly lower values:

#And now let's check the summary to see if there were any changes
tidy(aim2_reduced_final)
```

### Linearity of Log/Link Function:

```{r}

# Let's assess the linearity of the log/link

# We'll start by creating a dataset of the model's data
model_data <- model.frame(aim2_reduced_final)

# Now I want the predicted probabilities
pred_probs <- predict(aim2_reduced_final, type = "probs")  # matrix with one column per outcome
head(pred_probs)

model_data <- cbind(model_data, pred_probs)   # combine with model data

# Switch to long form:
model_data_long <- model_data %>%
  pivot_longer(
    cols = all_of(colnames(pred_probs)),  # the outcome columns
    names_to = "tx_group_level",
    values_to = "predicted_prob"
  )

# Then plot the loess function by faceting the graph by treatment group

ggplot(model_data_long, aes(x = age_std, y = predicted_prob)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", se = TRUE) +
  facet_wrap(~ tx_group_level) +
  labs(
    title = "Predicted Probabilities by Age (Standardized)",
    x = "Standardized Age",
    y = "Predicted Probability"
  )

# These all look "ROUGHLY" linear. Given that age is just a supporting covariate, I think this is sufficient to continue.



```

In this case, let's just use the log transformed model instead to better fit out model.

```{r}
aim2_reduced_final <- multinom(tx_group ~ pat_region + age_std + sex, data = data2_clean)

tidy(aim2_reduced_final)
```

# Final Results:

```{r}

#Before we report the final results, I want to also have a value where Rasagiline is the reference, so we can see the odds of patients being on Levodopa.

data2_clean$tx_group2 <- relevel(data2_clean$tx_group, ref = "Rasagiline")

aim2_reduced_final <- multinom(tx_group2 ~ pat_region + age_std + sex, data = data2_clean)

tidy(aim2_reduced_final)

```

We have found striking differences between which individuals are using certain medication parings in Aim 2. Our primary findings are:

**When controlling for Age and Sex:**

-   Individuals were not more likely to be taking pramipexole over Levodopa monotherapy in any part of the country when compared to the Midwest (NE = -.10, South = ., West = .12)

-   Individuals were more likely to be taking Rasagiline over levodopa monotherapy in almost every region of the country ((NE = 2.24 times, p = .02), (S = 1.82 times), p = .07), (West = 3.03 times, p \< .001)) when compared to the Midwest.

-   When holding rasagiline as the reference: Individuals taking Levodopa were .44 (56% lower) times less likely to be taking rasagiline in the midwest than in the Northeast (p = .02), 0.54 times less likely (46% lower) to be taking rasagiline in the midwest than in the south (p = .06), and 0.32 times less likely to be taking rasagiline in the midwest compared to the west (p = .0007) or 68% lower.

    ```{r}
    exp(-.18)
    ```

**When controlling for Region:**

-   Scaled age was approaching significance for the comparison of pramipexole and levodopa. A 1-unit standard deviation increase in log age was associated with a 0.98 times decrease in odds of using pramipexole over levodopa therapy (p = .09)

-   Scaled Age was significant for the comparison of rasagiline and levodopa. A 1 standard deviation increase in log age was associated with a 0.96 times decrease in odds of using rasagiline over levodopa therapy (p = .007)

-   Sex was significant for the comparison of pramipexole and levodopa. Male patients were 0.84 times (16% decrease) less likely to be receiving pramipexole over levodopa therapy.

-   Sex was significant for the comparison of Rasagiline and Levodopa. Male patients were 0.55 (45% decrease times less likely to be receiving rasagiline over levodopa therapy.

## Final Review:

Overall, we found that rasagiline dual-therapy with Levodopa shows strong evidence for clinical effectiveness in reducing the onset of dyskinesia in Early PD patients. However, despite this confirmation, regional distributions reveal that the vast majority of patients are using Levodopa monotherapy.

However, certain regions are at greater offense than others. The midwest was by-and-large the worst offender. Whereas western states had the lowest proportion of patients on Dual-Therapy, and the highest proportion of patients on Rasagiline Dual-Therapy.

Age and Sex were also a factor in this regionla distribution. Age was associate with decreased odds of taking a Dual therapy. This makes clinical sense, as older patients are more likely to be retired, not need to function optimally for employment, and already experience higher pill burden. The marginal effects gained by taking another pill make be outweighed by the cognitive load.

Sex however, revealed that men were significantly less likely to be taking any form of dual therapy than women when controlling for age and region. This may be due to clinical underreporting by the patients, cultural factors, or an unmeasured variable. Regardless, it is an interesting finding nontheless.
